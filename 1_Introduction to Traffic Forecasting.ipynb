{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TRAFFIX"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Introduction of Traffic Forecasting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Problem Definition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The traffic forecasting problem can be considered as learning a function/model $F$ to mapping historical traffic state data to predict the states in future time step/steps."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Please note: traffic states normally refer to as travel time, speed, volume, and etc. Some exiting studies also attempted to forecast the amount of origin-desination (O-D) pairs and metro ridership."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When attempting to predict network-wide traffic states, we usually convert the traffic states of the whole traffic network with $N$ roads/links/sensor stations as a vector $x\\in R^N$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A sequence of historical traffic state data with $T$ time steps can be represented by $X=[x_1, x_x, ..., x_T]$. Here, we assume those traffic states have the identical time interval $\\Delta t$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The future traffic states to be prediced can be one-step data $x_{T+1}$ or multi-steps data $[x_{T+1}, x_{T+2}, ..., x_{T+n}]$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following figure shows the process of forecasting one future step of traffic states:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"img/TrafficForecasting.PNG\" alt=\"drawing\" width=\"600\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hence, the traffic forecasting problem can be defined as learning a function $F$ such that "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{align}\n",
    "F([x_1, x_2, ..., x_T]) = [x_T]\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "or"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{align}\n",
    "F([x_1, x_2, ..., x_T]) = [x_{T+1}, x_{T+2}, ..., x_{T+n}]\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Traffic State Dataset Demo and Formatting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Taking the Seattle freeway loop detector data as an example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Dataset Description**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data is collected by the inductive loop detectors deployed on freeways in Seattle area. The freeways contains I-5, I-405, I-90, and SR-520, shown in the above picture. This dataset contains spatio-temporal speed information of the freeway system. In the picture, each blue icon demonstrates loop detectors at a milepost. The speed information at a milepost is averaged from multiple loop detectors on the mainlanes in a same direction at the specific milepost. The time interval of the dataset is 5-minute."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset can be downloaded from [GitHub](https://github.com/zhiyongc/Seattle-Loop-Data) or [Zenodo](https://zenodo.org/record/3258904#.Xeb9HldKi70). \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Region of data collected** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"img/SeattleLoopData.png\" alt=\"drawing\" width=\"400\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Dataset meta information**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|Attributes | values |\n",
    "|:---|:---|\n",
    "|Number of loop detector stations | 323 |\n",
    "|Time range | 2015-01-01 00:00:00 to 2015-12-31 23:55:00|\n",
    "|Time interval | 5 miniuts|\n",
    "|Unit of speed values| mile per hour (mph)|\n",
    "|Precision of speed values (GitHub version)| Rounded to the 6th decimal|\n",
    "|Precision of speed values (Zenodo version)| Rounded to integers|\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the Zenodo version, the speed values with a unit of mile per hour (mph) are formatted into integers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2.1 Read data "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "- [ ] Read data from google drive \n",
    "\n",
    "Coming soon!\n",
    " \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [x] Read data from local files\n",
    "\n",
    "The downloaded file of the Zenodo version named \"speed_matrix_2015_1mph\" is a Python pickled file that can be read by using Pandas.read_pickle(): \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we load the data from the local file and show the top 5 rows as a demonstration:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>ID</th>\n",
       "      <th>d005es15036</th>\n",
       "      <th>d005es15125</th>\n",
       "      <th>d005es15214</th>\n",
       "      <th>d005es15280</th>\n",
       "      <th>d005es15315</th>\n",
       "      <th>d005es15348</th>\n",
       "      <th>d005es15410</th>\n",
       "      <th>d005es15465</th>\n",
       "      <th>d005es15531</th>\n",
       "      <th>d005es15569</th>\n",
       "      <th>...</th>\n",
       "      <th>i520es00526</th>\n",
       "      <th>i520es00560</th>\n",
       "      <th>i520es00624</th>\n",
       "      <th>i520es00684</th>\n",
       "      <th>i520es00714</th>\n",
       "      <th>i520es00746</th>\n",
       "      <th>i520es00770</th>\n",
       "      <th>i520es00861</th>\n",
       "      <th>i520es00935</th>\n",
       "      <th>i520es00972</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stamp</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2015-01-01 00:00:00</th>\n",
       "      <td>62</td>\n",
       "      <td>64</td>\n",
       "      <td>62</td>\n",
       "      <td>61</td>\n",
       "      <td>63</td>\n",
       "      <td>64</td>\n",
       "      <td>63</td>\n",
       "      <td>65</td>\n",
       "      <td>63</td>\n",
       "      <td>65</td>\n",
       "      <td>...</td>\n",
       "      <td>64</td>\n",
       "      <td>60</td>\n",
       "      <td>62</td>\n",
       "      <td>62</td>\n",
       "      <td>64</td>\n",
       "      <td>64</td>\n",
       "      <td>62</td>\n",
       "      <td>68</td>\n",
       "      <td>67</td>\n",
       "      <td>62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-01-01 00:05:00</th>\n",
       "      <td>59</td>\n",
       "      <td>65</td>\n",
       "      <td>65</td>\n",
       "      <td>66</td>\n",
       "      <td>59</td>\n",
       "      <td>62</td>\n",
       "      <td>66</td>\n",
       "      <td>65</td>\n",
       "      <td>61</td>\n",
       "      <td>66</td>\n",
       "      <td>...</td>\n",
       "      <td>64</td>\n",
       "      <td>64</td>\n",
       "      <td>65</td>\n",
       "      <td>60</td>\n",
       "      <td>64</td>\n",
       "      <td>48</td>\n",
       "      <td>54</td>\n",
       "      <td>59</td>\n",
       "      <td>59</td>\n",
       "      <td>61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-01-01 00:10:00</th>\n",
       "      <td>62</td>\n",
       "      <td>65</td>\n",
       "      <td>65</td>\n",
       "      <td>64</td>\n",
       "      <td>62</td>\n",
       "      <td>64</td>\n",
       "      <td>60</td>\n",
       "      <td>65</td>\n",
       "      <td>64</td>\n",
       "      <td>66</td>\n",
       "      <td>...</td>\n",
       "      <td>60</td>\n",
       "      <td>64</td>\n",
       "      <td>57</td>\n",
       "      <td>63</td>\n",
       "      <td>64</td>\n",
       "      <td>58</td>\n",
       "      <td>59</td>\n",
       "      <td>59</td>\n",
       "      <td>57</td>\n",
       "      <td>57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-01-01 00:15:00</th>\n",
       "      <td>62</td>\n",
       "      <td>65</td>\n",
       "      <td>67</td>\n",
       "      <td>64</td>\n",
       "      <td>66</td>\n",
       "      <td>65</td>\n",
       "      <td>62</td>\n",
       "      <td>66</td>\n",
       "      <td>62</td>\n",
       "      <td>66</td>\n",
       "      <td>...</td>\n",
       "      <td>65</td>\n",
       "      <td>66</td>\n",
       "      <td>62</td>\n",
       "      <td>58</td>\n",
       "      <td>56</td>\n",
       "      <td>60</td>\n",
       "      <td>57</td>\n",
       "      <td>64</td>\n",
       "      <td>58</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-01-01 00:20:00</th>\n",
       "      <td>62</td>\n",
       "      <td>65</td>\n",
       "      <td>67</td>\n",
       "      <td>65</td>\n",
       "      <td>66</td>\n",
       "      <td>65</td>\n",
       "      <td>65</td>\n",
       "      <td>63</td>\n",
       "      <td>62</td>\n",
       "      <td>65</td>\n",
       "      <td>...</td>\n",
       "      <td>66</td>\n",
       "      <td>61</td>\n",
       "      <td>62</td>\n",
       "      <td>63</td>\n",
       "      <td>63</td>\n",
       "      <td>63</td>\n",
       "      <td>55</td>\n",
       "      <td>63</td>\n",
       "      <td>63</td>\n",
       "      <td>65</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 323 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "ID                   d005es15036  d005es15125  d005es15214  d005es15280  \\\n",
       "stamp                                                                     \n",
       "2015-01-01 00:00:00           62           64           62           61   \n",
       "2015-01-01 00:05:00           59           65           65           66   \n",
       "2015-01-01 00:10:00           62           65           65           64   \n",
       "2015-01-01 00:15:00           62           65           67           64   \n",
       "2015-01-01 00:20:00           62           65           67           65   \n",
       "\n",
       "ID                   d005es15315  d005es15348  d005es15410  d005es15465  \\\n",
       "stamp                                                                     \n",
       "2015-01-01 00:00:00           63           64           63           65   \n",
       "2015-01-01 00:05:00           59           62           66           65   \n",
       "2015-01-01 00:10:00           62           64           60           65   \n",
       "2015-01-01 00:15:00           66           65           62           66   \n",
       "2015-01-01 00:20:00           66           65           65           63   \n",
       "\n",
       "ID                   d005es15531  d005es15569  ...  i520es00526  i520es00560  \\\n",
       "stamp                                          ...                             \n",
       "2015-01-01 00:00:00           63           65  ...           64           60   \n",
       "2015-01-01 00:05:00           61           66  ...           64           64   \n",
       "2015-01-01 00:10:00           64           66  ...           60           64   \n",
       "2015-01-01 00:15:00           62           66  ...           65           66   \n",
       "2015-01-01 00:20:00           62           65  ...           66           61   \n",
       "\n",
       "ID                   i520es00624  i520es00684  i520es00714  i520es00746  \\\n",
       "stamp                                                                     \n",
       "2015-01-01 00:00:00           62           62           64           64   \n",
       "2015-01-01 00:05:00           65           60           64           48   \n",
       "2015-01-01 00:10:00           57           63           64           58   \n",
       "2015-01-01 00:15:00           62           58           56           60   \n",
       "2015-01-01 00:20:00           62           63           63           63   \n",
       "\n",
       "ID                   i520es00770  i520es00861  i520es00935  i520es00972  \n",
       "stamp                                                                    \n",
       "2015-01-01 00:00:00           62           68           67           62  \n",
       "2015-01-01 00:05:00           54           59           59           61  \n",
       "2015-01-01 00:10:00           59           59           57           57  \n",
       "2015-01-01 00:15:00           57           64           58           64  \n",
       "2015-01-01 00:20:00           55           63           63           65  \n",
       "\n",
       "[5 rows x 323 columns]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "speed_matrix =  pd.read_pickle('speed_matrix_2015_1mph')\n",
    "speed_matrix.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data is formatted into a matrix, whose horizontal and vertical axes display loop detector names and timestamps. \n",
    "\n",
    "The **temporal dimension** of the dataset is 105120 and the **spatial dimension** is 323. \n",
    "\n",
    "Here, the temporal dimension is 105120 = 365 (days) * 24 (hours) * 12 (5-minutes)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(105120, 323)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "speed_matrix.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2.2 Format data into training, validation, and testing sets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We first convert the data matrix into three sub-sets, i.e the training, validation, and testing sets. \n",
    "\n",
    "Normally, the **Training : Validation : Testing** ratio can be **7:2:1** or **6:2:2**.  \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some meta parameters are listed as below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 40\n",
    "seq_len = 10\n",
    "pred_len = 1\n",
    "train_propotion = 0.7\n",
    "valid_propotion = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 23996,  16147,   6243, ..., 100844,  74641,  71611])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(1024)\n",
    "index = np.arange(sample_size, dtype = int)\n",
    "np.random.shuffle(index)\n",
    "index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_len = speed_matrix.shape[0]\n",
    "\n",
    "max_speed = speed_matrix.max().max()\n",
    "speed_matrix =  speed_matrix / max_speed\n",
    "\n",
    "speed_sequences, speed_labels = [], []\n",
    "for i in range(time_len - seq_len - pred_len):\n",
    "    speed_sequences.append(speed_matrix.iloc[i:i+seq_len].values)\n",
    "    speed_labels.append(speed_matrix.iloc[i+seq_len:i+seq_len+pred_len].values)\n",
    "speed_sequences, speed_labels = np.asarray(speed_sequences), np.asarray(speed_labels)\n",
    "\n",
    "# shuffle and split the dataset to training and testing datasets\n",
    "sample_size = speed_sequences.shape[0]\n",
    "index = np.arange(sample_size, dtype = int)\n",
    "np.random.shuffle(index)\n",
    "\n",
    "train_index = int(np.floor(sample_size * train_propotion))\n",
    "valid_index = int(np.floor(sample_size * ( train_propotion + valid_propotion)))\n",
    "\n",
    "train_data, train_label = speed_sequences[:train_index], speed_labels[:train_index]\n",
    "valid_data, valid_label = speed_sequences[train_index:valid_index], speed_labels[train_index:valid_index]\n",
    "test_data, test_label = speed_sequences[valid_index:], speed_labels[valid_index:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def PrepareDataset(speed_matrix, BATCH_SIZE = 40, seq_len = 10, pred_len = 1, train_propotion = 0.7, valid_propotion = 0.2):\n",
    "    \"\"\" Prepare training and testing datasets and dataloaders.\n",
    "    \n",
    "    Convert speed/volume/occupancy matrix to training, validation, and testing sets. \n",
    "    The vertical axis of speed_matrix is the time axis and the horizontal axis \n",
    "    is the spatial axis.\n",
    "    \n",
    "    Args:\n",
    "        speed_matrix: a Matrix containing spatial-temporal speed data for a network\n",
    "        seq_len: length of input sequence\n",
    "        pred_len: length of predicted sequence\n",
    "    Returns:\n",
    "        Training dataloader\n",
    "        Testing dataloader\n",
    "    \"\"\"\n",
    "    \n",
    "    np.random.seed(1024)\n",
    "    \n",
    "    time_len = speed_matrix.shape[0]\n",
    "    \n",
    "    max_speed = speed_matrix.max().max()\n",
    "    speed_matrix =  speed_matrix / max_speed\n",
    "    \n",
    "    speed_sequences, speed_labels = [], []\n",
    "    for i in range(time_len - seq_len - pred_len):\n",
    "        speed_sequences.append(speed_matrix.iloc[i:i+seq_len].values)\n",
    "        speed_labels.append(speed_matrix.iloc[i+seq_len:i+seq_len+pred_len].values)\n",
    "    speed_sequences, speed_labels = np.asarray(speed_sequences), np.asarray(speed_labels)\n",
    "    \n",
    "    # shuffle and split the dataset to training and testing datasets\n",
    "    sample_size = speed_sequences.shape[0]\n",
    "    index = np.arange(sample_size, dtype = int)\n",
    "    np.random.shuffle(index)\n",
    "    \n",
    "    train_index = int(np.floor(sample_size * train_propotion))\n",
    "    valid_index = int(np.floor(sample_size * ( train_propotion + valid_propotion)))\n",
    "    \n",
    "    train_data, train_label = speed_sequences[:train_index], speed_labels[:train_index]\n",
    "    valid_data, valid_label = speed_sequences[train_index:valid_index], speed_labels[train_index:valid_index]\n",
    "    test_data, test_label = speed_sequences[valid_index:], speed_labels[valid_index:]\n",
    "    \n",
    "    train_data, train_label = torch.Tensor(train_data), torch.Tensor(train_label)\n",
    "    valid_data, valid_label = torch.Tensor(valid_data), torch.Tensor(valid_label)\n",
    "    test_data, test_label = torch.Tensor(test_data), torch.Tensor(test_label)\n",
    "    \n",
    "    train_dataset = utils.TensorDataset(train_data, train_label)\n",
    "    valid_dataset = utils.TensorDataset(valid_data, valid_label)\n",
    "    test_dataset = utils.TensorDataset(test_data, test_label)\n",
    "    \n",
    "    train_dataloader = utils.DataLoader(train_dataset, batch_size = BATCH_SIZE, shuffle=True, drop_last = True)\n",
    "    valid_dataloader = utils.DataLoader(valid_dataset, batch_size = BATCH_SIZE, shuffle=True, drop_last = True)\n",
    "    test_dataloader = utils.DataLoader(test_dataset, batch_size = BATCH_SIZE, shuffle=True, drop_last = True)\n",
    "    \n",
    "    return train_dataloader, valid_dataloader, test_dataloader, max_speed"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
